name: CI Host

on:
  push:
    branches: [main]
  pull_request:
    paths:
      - "packages/host/**"
      - "packages/base/**"
      - "packages/boxel-icons/**"
      - "packages/boxel-ui/**"
      - "packages/catalog-realm/**"
      - "packages/eslint-plugin-boxel/**"
      - "packages/realm-server/**"
      - "packages/runtime-common/**"
      - ".github/workflows/ci-host.yml"
      - "package.json"
      - "pnpm-lock.yaml"
  workflow_dispatch:

permissions:
  checks: write
  contents: read
  id-token: write
  pull-requests: write

jobs:
  host-test:
    name: Host Tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - shardIndex: 1
            shardTotal: 2
          - shardIndex: 2
            shardTotal: 2
    concurrency:
      group: boxel-host-test${{ github.head_ref || github.run_id }}-shard${{ matrix.shardIndex }}
      cancel-in-progress: true
    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.2.2
      - uses: ./.github/actions/init
      - name: Build boxel-icons
        run: pnpm build
        working-directory: packages/boxel-icons
      - name: Serve boxel-icons
        run: pnpm serve &> /tmp/icon-server.log &
        working-directory: packages/boxel-icons
      - name: Build boxel-ui
        run: pnpm build
        working-directory: packages/boxel-ui/addon
      # this is to hopefully address the CI network flakiness that we
      # occasionally see in host tests.
      # https://github.com/actions/runner-images/issues/1187#issuecomment-686735760
      - name: Disable TCP/UDP network offloading
        run: sudo ethtool -K eth0 tx off rx off
      - name: Start host to serve assets for fastboot
        uses: JarvusInnovations/background-action@2428e7b970a846423095c79d43f759abf979a635 # 1.0.7
        with:
          run: NODE_OPTIONS="--max_old_space_size=4096" pnpm start &
          working-directory: packages/host
          wait-for: 3m
          wait-on: http-get://localhost:4200
      - name: Start realm servers
        run: pnpm start:skip-experiments | tee -a /tmp/server.log &
        working-directory: packages/realm-server
      - name: create realm users
        run: pnpm register-realm-users
        working-directory: packages/matrix
      - name: host test suite (shard ${{ matrix.shardIndex }})
        run: pnpm test-with-percy
        env:
          PERCY_GZIP: true
          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN_HOST }}
          PERCY_PARALLEL_NONCE: ${{ github.run_id }}-${{ github.run_attempt }}
          HOST_TEST_PARTITION: ${{ matrix.shardIndex }}
          HOST_TEST_PARTITION_COUNT: ${{ matrix.shardTotal }}
        working-directory: packages/host
      - name: Upload junit report to GitHub Actions Artifacts
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-test-report-${{ matrix.shardIndex }}
          path: junit/host-${{ matrix.shardIndex }}.xml
          retention-days: 30
      - name: Print realm server logs
        if: always()
        run: cat /tmp/server.log
      - name: Upload realm server log
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: realm-server-log-${{ matrix.shardIndex }}
          path: /tmp/server.log
          retention-days: 30
      - name: Upload icon server log
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: icon-server-log-${{ matrix.shardIndex }}
          path: /tmp/icon-server.log
          retention-days: 30

  host-merge-reports-and-publish:
    name: Merge Host reports and publish
    if: always()
    needs: host-test
    runs-on: ubuntu-latest
    outputs:
      fail_count_first: ${{ steps.collect.outputs.fail_count }}
      should_rerun: ${{ steps.determine.outputs.should_rerun }}
      should_rerun_reason: ${{ steps.determine.outputs.reason }}

    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.2.2
      - uses: ./.github/actions/init

      - name: Finalise Percy
        run: npx percy build:finalize
        working-directory: packages/host
        env:
          PERCY_TOKEN: ${{ secrets.PERCY_TOKEN_HOST }}
          PERCY_PARALLEL_NONCE: ${{ github.run_id }}-${{ github.run_attempt }}

      - name: Download JUnit reports from GitHub Actions Artifacts
        uses: actions/download-artifact@b14cf4c92620c250e1c074ab0a5800e37df86765 # 4.2.0
        with:
          path: all-host-reports
          pattern: host-test-report-*
          merge-multiple: true

      - run: ls
      - run: ls all-host-reports

      - name: Merge reports
        run: npx junit-report-merger host.xml "./all-host-reports/*.xml"

      # host.xml has classname="Chrome 134.0", change to classname="Chrome" to prevent false test removal/addition warnings
      - name: Remove Chrome version number
        run: sed -i -E 's/classname="Chrome [^"]*"/classname="Chrome"/' host.xml

      - name: Upload merged report
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-test-report-merged
          path: host.xml
          retention-days: 30

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@170bf24d20d201b842d7a52403b73ed297e6645b # 2.18.0
        if: always()
        with:
          junit_files: host.xml
          check_name: Host Test Results

      - name: Collect failed modules
        id: collect
        run: |
          summary=$(node scripts/ci/collect-failures.js --input host.xml --tests failed-tests.json --modules failed-modules.json)
          echo "Collected failure summary: $summary"
          echo "summary=$summary" >> "$GITHUB_OUTPUT"
          echo "fail_count=$(echo "$summary" | jq -r '.count')" >> "$GITHUB_OUTPUT"
          echo "modules_count=$(echo "$summary" | jq -r '.modules')" >> "$GITHUB_OUTPUT"
          echo "$summary" > failure-summary.json

      - name: Determine rerun eligibility
        id: determine
        run: |
          node <<'NODE'
          const summary = JSON.parse(process.env.SUMMARY ?? '{}');
          const count = Number(summary.count ?? 0);
          const modules = Number(summary.modules ?? 0);
          const shouldRerun = count >= 1 && count <= 999 && modules > 0;

          const fs = require('node:fs');
          const output = process.env.GITHUB_OUTPUT;
          let reason;
          if (!Number.isFinite(count)) {
            reason = `First pass failure count was not a number: ${summary.count}`;
          } else if (count <= 0) {
            reason = `No first pass failures detected (count=${count}).`;
          } else if (count > 999) {
            reason = `First pass failure count ${count} exceeds rerun threshold.`;
          } else if (!Number.isFinite(modules)) {
            reason = `Failed module count was not a number: ${summary.modules}`;
          } else if (modules === 0) {
            reason = `No failed modules available for rerun (modules=${modules}).`;
          } else {
            reason = `Eligible for rerun with ${count} failing tests across ${modules} modules.`;
          }

          fs.appendFileSync(output, `should_rerun=${shouldRerun}\n`);
          fs.appendFileSync(output, `modules_count=${modules}\n`);
          let safeReason = String(reason ?? '').replace(/[\r\n]+/g, ' ').trim();
          if (!safeReason) {
            safeReason = 'No rerun decision reason recorded.';
          }
          fs.appendFileSync(output, `reason=${safeReason}\n`);

          console.log(`[rerun-decision] count=${count} modules=${modules} should_rerun=${shouldRerun}`);
          console.log(`[rerun-decision] ${reason}`);
          NODE
        env:
          SUMMARY: ${{ steps.collect.outputs.summary }}

      - name: Record first pass summary
        run: |
          echo "First pass failing tests: ${{ steps.collect.outputs.fail_count }}"
          echo "Rerun decision: ${{ steps.determine.outputs.should_rerun }}"
          echo "Reason: ${{ steps.determine.outputs.reason }}"
          echo "First pass failing tests: ${{ steps.collect.outputs.fail_count }}" >> "$GITHUB_STEP_SUMMARY"
          echo "Rerun decision: ${{ steps.determine.outputs.should_rerun }}" >> "$GITHUB_STEP_SUMMARY"
          echo "Reason: ${{ steps.determine.outputs.reason }}" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload failure summary
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-failure-summary
          path: failure-summary.json
          retention-days: 30

      - name: Upload failed test listing
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-failed-tests
          path: failed-tests.json
          retention-days: 30

      - name: Upload failed modules
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-failed-modules
          path: failed-modules.json
          retention-days: 30

  host-rerun-failed-modules:
    name: Host rerun failed modules
    needs: host-merge-reports-and-publish
    if: ${{ needs.host-merge-reports-and-publish.outputs.should_rerun == 'true' }}
    runs-on: ubuntu-latest
    outputs:
      fail_count_second: ${{ steps.collect-rerun.outputs.fail_count }}

    steps:
      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # 4.2.2
      - uses: ./.github/actions/init

      - name: Download failed modules
        uses: actions/download-artifact@b14cf4c92620c250e1c074ab0a5800e37df86765 # 4.2.0
        with:
          name: host-failed-modules
          path: rerun-data

      - name: Show modules queued for rerun
        run: |
          echo "Modules slated for rerun:"
          if [ -f rerun-data/failed-modules.json ]; then
            cat rerun-data/failed-modules.json
          else
            echo "(missing rerun-data/failed-modules.json)"
          fi

      - name: Build boxel-icons
        run: pnpm build
        working-directory: packages/boxel-icons

      - name: Serve boxel-icons
        run: pnpm serve &> /tmp/icon-server.log &
        working-directory: packages/boxel-icons

      - name: Build boxel-ui
        run: pnpm build
        working-directory: packages/boxel-ui/addon

      - name: Disable TCP/UDP network offloading
        run: sudo ethtool -K eth0 tx off rx off

      - name: Start host to serve assets for fastboot
        uses: JarvusInnovations/background-action@2428e7b970a846423095c79d43f759abf979a635 # 1.0.7
        with:
          run: NODE_OPTIONS="--max_old_space_size=4096" pnpm start &
          working-directory: packages/host
          wait-for: 3m
          wait-on: http-get://localhost:4200

      - name: Start realm servers
        run: pnpm start:skip-experiments | tee -a /tmp/server.log &
        working-directory: packages/realm-server

      - name: create realm users
        run: pnpm register-realm-users
        working-directory: packages/matrix

      - name: Rerun failed modules
        id: rerun-tests
        continue-on-error: true
        working-directory: packages/host
        env:
          HOST_TEST_PARTITION: rerun
          HOST_TEST_PARTITION_COUNT: 1
        run: |
          readarray -t modules < <(jq -r '.[]' ../rerun-data/failed-modules.json)
          if [ "${#modules[@]}" -eq 0 ]; then
            echo "No modules provided for rerun." >&2
            exit 0
          fi
          BASE_REALM="http-get://localhost:4201/base/"
          CATALOG_REALM="http-get://localhost:4201/catalog/"
          NODE_TEST_REALM="http-get://localhost:4202/node-test/"
          SKILLS_REALM="http-get://localhost:4201/skills/"
          TEST_REALM="http-get://localhost:4202/test/"
          READY_PATH="_readiness-check?acceptHeader=application%2Fvnd.api%2Bjson"
          READY_ENDPOINTS="$BASE_REALM$READY_PATH|$CATALOG_REALM$READY_PATH|$NODE_TEST_REALM$READY_PATH|$SKILLS_REALM$READY_PATH|$TEST_REALM$READY_PATH|http://localhost:8008|http://localhost:5001"

          cmd=(pnpm exec ember exam)
          for module in "${modules[@]}"; do
            cmd+=(--module "$module")
          done

          echo "Re-running ${#modules[@]} modules:"
          for module in "${modules[@]}"; do
            echo "  - $module"
          done

          printf -v command_str '%q ' "${cmd[@]}"
          echo "Executing rerun command: $command_str"
          NODE_NO_WARNINGS=1 pnpm exec start-server-and-test 'pnpm run wait' "$READY_ENDPOINTS" "$command_str"

      - name: Rename rerun junit
        if: always()
        run: |
          if [ -f junit/host-rerun.xml ]; then
            mv junit/host-rerun.xml junit/junit-rerun.xml
          fi
        working-directory: packages/host

      - name: Collect rerun failures
        id: collect-rerun
        if: always()
        run: |
          summary=$(node scripts/ci/collect-failures.js --input packages/host/junit/junit-rerun.xml --tests rerun-failed-tests.json --modules rerun-failed-modules.json)
          echo "Rerun failure summary: $summary"
          echo "summary=$summary" >> "$GITHUB_OUTPUT"
          echo "fail_count=$(echo "$summary" | jq -r '.count')" >> "$GITHUB_OUTPUT"
          echo "$summary" > rerun-failure-summary.json

      - name: Record second pass summary
        if: always()
        run: |
          echo "Second pass failing tests: ${{ steps.collect-rerun.outputs.fail_count }}" >> "$GITHUB_STEP_SUMMARY"

      - name: Upload rerun junit report
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-test-report-rerun
          path: packages/host/junit/junit-rerun.xml
          retention-days: 30

      - name: Upload rerun failed tests
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: steps.collect-rerun.outputs.fail_count != '0'
        with:
          name: host-rerun-failed-tests
          path: rerun-failed-tests.json
          retention-days: 30

      - name: Upload rerun failure summary
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-rerun-failure-summary
          path: rerun-failure-summary.json
          retention-days: 30

      - name: Print rerun realm server logs
        if: always()
        run: cat /tmp/server.log

      - name: Upload rerun realm server log
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-rerun-realm-server-log
          path: /tmp/server.log
          retention-days: 30

      - name: Upload rerun icon server log
        uses: actions/upload-artifact@4cec3d8aa04e39d1a68397de0c4cd6fb9dce8ec1 # 4.6.1
        if: always()
        with:
          name: host-rerun-icon-server-log
          path: /tmp/icon-server.log
          retention-days: 30

  host-final-gate:
    name: Host rerun gate
    needs:
      - host-merge-reports-and-publish
      - host-rerun-failed-modules
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Summarize outcome
        run: |
          first_count='${{ needs.host-merge-reports-and-publish.outputs.fail_count_first }}'
          if [ -z "$first_count" ]; then
            first_count=0
          fi

          should_rerun='${{ needs.host-merge-reports-and-publish.outputs.should_rerun }}'
          if [ -z "$should_rerun" ]; then
            should_rerun=false
          fi

          echo "First pass failures: $first_count"
          echo "Rerun eligibility: $should_rerun"
          echo "Eligibility reason: ${{ needs.host-merge-reports-and-publish.outputs.should_rerun_reason }}"
          echo "First pass failures: $first_count" >> "$GITHUB_STEP_SUMMARY"
          echo "Rerun eligibility: $should_rerun" >> "$GITHUB_STEP_SUMMARY"
          echo "Eligibility reason: ${{ needs.host-merge-reports-and-publish.outputs.should_rerun_reason }}" >> "$GITHUB_STEP_SUMMARY"

          second_count=0
          if [ "$should_rerun" = "true" ]; then
            rerun_result='${{ needs.host-rerun-failed-modules.result }}'
            echo "Rerun job result: $rerun_result"
            echo "Rerun job result: $rerun_result" >> "$GITHUB_STEP_SUMMARY"
            if [ "$rerun_result" = "skipped" ]; then
              echo "Rerun job was skipped unexpectedly."
              echo "Rerun job was skipped unexpectedly." >> "$GITHUB_STEP_SUMMARY"
            fi
            if [ "$rerun_result" != "success" ]; then
              echo "Rerun job did not complete successfully: $rerun_result"
              echo "Rerun job did not complete successfully: $rerun_result" >> "$GITHUB_STEP_SUMMARY"
              exit 1
            fi
            second_count='${{ needs.host-rerun-failed-modules.outputs.fail_count_second }}'
            if [ -z "$second_count" ]; then
              second_count=0
            fi
            echo "Second pass failures: $second_count"
            echo "Second pass failures: $second_count" >> "$GITHUB_STEP_SUMMARY"
            if [ "$second_count" -eq 0 ]; then
              echo "Rerun completed with no failures."
              echo "Rerun completed with no failures." >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            if [ "$first_count" -ge 1000 ]; then
              echo "Rerun: skipped (>=1000)"
              echo "Rerun: skipped (>=1000)" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "Rerun: skipped"
              echo "Rerun: skipped" >> "$GITHUB_STEP_SUMMARY"
            fi
          fi

          exit_code=0
          if [ "$first_count" -eq 0 ]; then
            exit_code=0
          elif [ "$first_count" -ge 1000 ]; then
            exit_code=1
          elif [ "$should_rerun" = "true" ] && [ "$second_count" -gt 0 ]; then
            exit_code=1
          elif [ "$should_rerun" != "true" ] && [ "$first_count" -gt 0 ]; then
            exit_code=1
          fi

          if [ "$exit_code" -ne 0 ]; then
            exit $exit_code
          fi
