{
  "data": {
    "type": "card",
    "attributes": {
      "modelId": "mistralai/mixtral-8x7b-instruct",
      "canonicalSlug": "mistralai/mixtral-8x7b-instruct",
      "name": "Mistral: Mixtral 8x7B Instruct",
      "created": 1702166400,
      "description": "Mixtral 8x7B Instruct is a pretrained generative Sparse Mixture of Experts, by Mistral AI, for chat and instruction use. Incorporates 8 experts (feed-forward networks) for a total of 47 billion parameters.\n\nInstruct model fine-tuned by Mistral. #moe",
      "pricing": {
        "prompt": "0.00000054",
        "completion": "0.00000054",
        "request": "0",
        "image": "0"
      },
      "contextLength": 32768,
      "architecture": {
        "modality": "text->text",
        "inputModalities": [
          "text"
        ],
        "outputModalities": [
          "text"
        ],
        "tokenizer": "Mistral",
        "instructType": "mistral"
      },
      "topProvider": {
        "isModerated": false,
        "contextLength": 32768,
        "maxCompletionTokens": 16384
      },
      "perRequestLimits": null,
      "supportedParameters": [
        "frequency_penalty",
        "logit_bias",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "defaultParameters": {
        "temperature": 0.3
      },
      "cardInfo": {
        "title": null,
        "description": null,
        "thumbnailURL": null,
        "notes": null
      }
    },
    "meta": {
      "adoptsFrom": {
        "module": "../openrouter-model",
        "name": "OpenRouterModel"
      }
    }
  }
}