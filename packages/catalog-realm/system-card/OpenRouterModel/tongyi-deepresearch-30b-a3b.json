{
  "data": {
    "type": "card",
    "attributes": {
      "modelId": "alibaba/tongyi-deepresearch-30b-a3b",
      "canonicalSlug": "alibaba/tongyi-deepresearch-30b-a3b",
      "name": "Tongyi DeepResearch 30B A3B",
      "created": 1758210804,
      "description": "Tongyi DeepResearch is an agentic large language model developed by Tongyi Lab, with 30 billion total parameters activating only 3 billion per token. It's optimized for long-horizon, deep information-seeking tasks and delivers state-of-the-art performance on benchmarks like Humanity's Last Exam, BrowserComp, BrowserComp-ZH, WebWalkerQA, GAIA, xbench-DeepSearch, and FRAMES. This makes it superior for complex agentic search, reasoning, and multi-step problem-solving compared to prior models.\n\nThe model includes a fully automated synthetic data pipeline for scalable pre-training, fine-tuning, and reinforcement learning. It uses large-scale continual pre-training on diverse agentic data to boost reasoning and stay fresh. It also features end-to-end on-policy RL with a customized Group Relative Policy Optimization, including token-level gradients and negative sample filtering for stable training. The model supports ReAct for core ability checks and an IterResearch-based 'Heavy' mode for max performance through test-time scaling. It's ideal for advanced research agents, tool use, and heavy inference workflows.",
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.0000004",
        "request": "0",
        "image": "0"
      },
      "contextLength": 131072,
      "architecture": {
        "modality": "text->text",
        "inputModalities": [
          "text"
        ],
        "outputModalities": [
          "text"
        ],
        "tokenizer": "Other",
        "instructType": ""
      },
      "topProvider": {
        "isModerated": false,
        "contextLength": 131072,
        "maxCompletionTokens": 131072
      },
      "perRequestLimits": null,
      "supportedParameters": [
        "frequency_penalty",
        "include_reasoning",
        "max_tokens",
        "min_p",
        "presence_penalty",
        "reasoning",
        "repetition_penalty",
        "response_format",
        "seed",
        "stop",
        "structured_outputs",
        "temperature",
        "tool_choice",
        "tools",
        "top_k",
        "top_p"
      ],
      "defaultParameters": {
        "temperature": null,
        "top_p": null,
        "frequency_penalty": null
      },
      "cardInfo": {
        "title": null,
        "description": null,
        "thumbnailURL": null,
        "notes": null
      }
    },
    "meta": {
      "adoptsFrom": {
        "module": "../openrouter-model",
        "name": "OpenRouterModel"
      }
    }
  }
}